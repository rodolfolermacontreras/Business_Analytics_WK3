{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Predicting Default Probability\n",
    "\n",
    "This notebook carries out the following steps\n",
    "  1. Reads the original data including all the fields added by Lending Club to predict default probability\n",
    "  2. Redo the prediction using only the fields available in our saved pickle file\n",
    "  3. Start with predicting default using only signals such as the grade or interest assigned to a loan by Lending Club\n",
    "  4. Redo the analysis only with variables available at the time of loan application\n",
    "  \n",
    "Things for you to do\n",
    "- Variable Selection for Tree and Logistic Regression Models\n",
    "- Tuning the Tree Model for Performance and Explanation\n",
    "- Tuning the Logistic Regression for Performance and Explanation\n",
    "- Model Comparison (Think about how you might choose one of these classifiers for downstream analysis of picking out the best loans to invest in. Will you use a batch, rank-ordered or customized assessment method to pick between these models? How much do you care about the interpretability of the chosen model in this decision?)\n",
    "- Optional: Try other models for prediction while answering the same questions as above (feature selection, tuning, explainability)\n",
    "- Optional: You may compare the default probabilities predicted from Step 4 above with the grades assigned by Lending Club to see if they capture the same signal as your models\n",
    "\n",
    "Prepare your presentation. Your presentation should contain at most 6 slides. Add an extra slide at the end if you tried the BONUS.\n",
    "\n",
    "1.  Begin by stating the objective of the presentation and what your objective is. Which questions do you seek to answer? What are the main points of the presentation?\n",
    "2. Feature engineering: Describe the results you got when there is data leakage. What is the final set of variables that you use? Did you generate your own variables? If so, explain what these variables capture.\n",
    "3. (4.) Provide an intuitive explanation of at least two predictive models tried. How do you think they are determining if a loan will default or not? Do these results help you better understand the problem or the data? Compare the results of the models in the context of their use in the investment problem. Which metric did you use to compare them and why? For the logistic regression, start with the ouput model data and rank the significant coeffs in decreasing order of importance\n",
    "5. State your conclusions. What is the main idea you wish to convey with the presentation? Do you think the findings from this script will be useful to solve the overall problem? What are the main takeaways of the analysis you performed?\n",
    "\n",
    "BONUS\n",
    "\n",
    "- Can you improve your models using the results from module 2? If so, clearly state the improvements in terms of the metric you used to evaluate your models.\n",
    "\n",
    "- Can you derive new variables from the original ones to improve your models? If so, clearly state the improvements in terms of the metric you used to evaluate your models.\n",
    "\n",
    "- Use a more sophisticated (although less interpretable) predictive model such as tree boosting or support vector machine to obtain new results. Do these models perform better?\n",
    "\n",
    "- Are there any exogenous variables (i.e. variables from other data sets, such as economic growth of the country) you might use to improve your models?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Load the raw data again and predict default from all available fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load general utilities\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, brier_score_loss, mean_squared_error, r2_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Load classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Load debugger, if required\n",
    "#import pixiedust\n",
    "pd.options.mode.chained_assignment = None #'warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.19</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read downloaded file(s) again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you are re-running the script again and want to load all the models you have computed already and stored\n",
    "# reload them from a saved dill file by uncommenting the next two lines and using the appropriate dill file name\n",
    "# import dill\n",
    "# dill.load_session('finalweek3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reading file LoanStats3b.csv\n",
      "    Reading file LoanStats3c.csv\n"
     ]
    }
   ],
   "source": [
    "# load the data from the file\n",
    "directory = 'C:\\\\Users\\\\ly266e\\\\Documents\\\\Training\\\\CMU\\\\Master\\\\Fall 2023 Mini 7\\\\Business_Analytics\\\\HW\\\\Data\\\\'\n",
    "all_files = os.listdir(directory)\n",
    "output = {}\n",
    "for i in all_files:\n",
    "    print(\"    Reading file \" + i)\n",
    "    output[i] = pd.read_csv(directory + i, dtype = str, skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423211, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([output[i] for i in output.keys()], join='inner')\n",
    "\n",
    "data = data[['id','loan_amnt','funded_amnt','funded_amnt_inv','term','int_rate',\n",
    "         'installment','grade','sub_grade','emp_title','emp_length',\n",
    "         'home_ownership','annual_inc','verification_status','issue_d',\n",
    "         'loan_status','purpose','title','zip_code','addr_state','dti','total_pymnt',\n",
    "         'delinq_2yrs','earliest_cr_line','open_acc','pub_rec','last_pymnt_d',\n",
    "         'last_pymnt_amnt','application_type','revol_bal','revol_util','recoveries']]\n",
    "\n",
    "data.dropna(subset=['annual_inc','loan_status','issue_d','last_pymnt_d','loan_amnt',\n",
    "                    'int_rate','earliest_cr_line','open_acc','pub_rec','delinq_2yrs',\n",
    "                    'recoveries','grade','installment','funded_amnt','dti','funded_amnt_inv',\n",
    "                    'revol_bal','revol_util'],inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the type of each of these column\n",
    "float_cols = ['loan_amnt', 'funded_amnt', 'installment', 'annual_inc',\n",
    "            'dti', 'revol_bal', 'delinq_2yrs', 'open_acc', 'pub_rec', 'total_pymnt', 'recoveries']\n",
    "\n",
    "cat_cols = ['term', 'grade', 'emp_length', 'home_ownership',\n",
    "            'verification_status', 'loan_status', 'purpose']\n",
    "\n",
    "perc_cols = ['int_rate', 'revol_util']\n",
    "\n",
    "date_cols = ['issue_d', 'earliest_cr_line', 'last_pymnt_d']\n",
    "\n",
    "for j in float_cols:\n",
    "    data[j] = pd.to_numeric(data[j])\n",
    "    \n",
    "for j in perc_cols:\n",
    "    data[j] = data[j].str.strip('%')\n",
    "    data[j] = pd.to_numeric(data[j])\n",
    "    data[j] = data[j]/100\n",
    "\n",
    "for j in date_cols:\n",
    "    data[j] = pd.to_datetime(data[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer the features and generate the training/testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 61)\n",
      "(1500, 61)\n"
     ]
    }
   ],
   "source": [
    "default_seed = 1\n",
    "np.random.seed(default_seed)\n",
    "\n",
    "# select only terminated loans\n",
    "data = data[data.loan_status.isin(['Fully Paid','Charged Off','Default'])]\n",
    "\n",
    "# downsample\n",
    "data = data.sample(n=5000)\n",
    "\n",
    "# create labels for the dataset\n",
    "data['label'] = (data.loan_status.str.contains('Charged Off') | \n",
    "                data.loan_status.str.contains('Default'))\n",
    "data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n",
    "data.label = data.label.astype(int)\n",
    "\n",
    "# clean and get training/testing data \n",
    "temp = pd.get_dummies(data[['term','grade','emp_length','home_ownership',\n",
    "                                  'verification_status','purpose']], dummy_na=True)\n",
    "subdata = data[['loan_amnt','funded_amnt','int_rate','installment',\n",
    "                'annual_inc','dti','delinq_2yrs','open_acc','pub_rec', 'cr_hist','revol_bal',\n",
    "                            'recoveries', 'revol_util', 'total_pymnt']]\n",
    "X = subdata.to_numpy()\n",
    "#X = data.as_matrix(columns=['loan_amnt','funded_amnt','int_rate','installment',\n",
    "#                            'annual_inc','dti','delinq_2yrs','open_acc','pub_rec',\n",
    "#                            'cr_hist','revol_bal',\n",
    "#                            'recoveries',\n",
    "#                            'revol_util', 'total_pymnt'])\n",
    "\n",
    "#X = np.concatenate((X,temp.as_matrix()),axis=1)\n",
    "X = np.concatenate((X,temp.to_numpy()),axis=1)\n",
    "\n",
    "#y = data.label.as_matrix()\n",
    "y = data.label.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $l_2$ penalized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=10, max_iter=2000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticModel = LogisticRegressionCV(cv=10,penalty='l2',max_iter=2000)\n",
    "logisticModel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9933333333333333\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Defaulted Loan     0.9927    0.9992    0.9959      1225\n",
      "    Defaulted Loan     0.9963    0.9673    0.9815       275\n",
      "\n",
      "          accuracy                         0.9933      1500\n",
      "         macro avg     0.9945    0.9832    0.9887      1500\n",
      "      weighted avg     0.9934    0.9933    0.9933      1500\n",
      "\n",
      "AUC:  0.9942441558441558\n"
     ]
    }
   ],
   "source": [
    "y_pred = logisticModel.predict(X_test)\n",
    "print('accuracy: ',accuracy_score(y_test,y_pred))\n",
    "target_names = ['Non-Defaulted Loan','Defaulted Loan']\n",
    "\n",
    "print(classification_report(y_test,y_pred,target_names=target_names,digits=4))\n",
    "print('AUC: ',roc_auc_score(y_test,logisticModel.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, logisticModel.predict_proba(X_test)[:,1],\n",
    "                                         pos_label=1)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% roc_auc_score(y_test,logisticModel.predict_proba(X_test)[:,1]))\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "In addition to logistic regression, let's also take a quick look at random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8706666666666667\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Non-Defaulted Loan     0.8633    1.0000    0.9266      1225\n",
      "    Defaulted Loan     1.0000    0.2945    0.4551       275\n",
      "\n",
      "          accuracy                         0.8707      1500\n",
      "         macro avg     0.9316    0.6473    0.6908      1500\n",
      "      weighted avg     0.8883    0.8707    0.8402      1500\n",
      "\n",
      "AUC:  0.9651562152133581\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(min_samples_leaf=100,n_estimators=50)\n",
    "random_forest.fit(X_train,y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print('accuracy: ',accuracy_score(y_test,y_pred))\n",
    "target_names = ['Non-Defaulted Loan','Defaulted Loan']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names,digits=4))\n",
    "print('AUC: ',roc_auc_score(y_test,random_forest.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, with leaked features the AUC of the prediction models is ridiculously high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Redo predictions with the columns stored in our pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\ly266e\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pydotplus\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       haa95532_0         123 KB\n",
      "    cairo-1.16.0               |       he04af86_2         1.5 MB\n",
      "    certifi-2023.7.22          |   py39haa95532_0         154 KB\n",
      "    expat-2.5.0                |       hd77b12b_0         225 KB\n",
      "    fribidi-1.0.10             |       h62dcd97_0          63 KB\n",
      "    getopt-win32-0.1           |       h2bbff1b_0          19 KB\n",
      "    glib-2.69.1                |       h5dc1a3c_1         1.6 MB\n",
      "    graphite2-1.3.14           |       hd77b12b_1          91 KB\n",
      "    graphviz-2.50.0            |       hdb8b0d4_0         903 KB\n",
      "    gts-0.7.6                  |       h63ab5a1_3         181 KB\n",
      "    harfbuzz-4.3.0             |       hb646838_1         855 KB\n",
      "    libffi-3.4.4               |       hd77b12b_0         113 KB\n",
      "    libgd-2.3.3                |       ha43c60c_1         314 KB\n",
      "    numexpr-2.8.4              |   py39h5b0cc5e_0         127 KB\n",
      "    openssl-1.1.1w             |       h2bbff1b_0         5.5 MB\n",
      "    pango-1.50.7               |       h78c2152_0         279 KB\n",
      "    pcre-8.45                  |       hd77b12b_0         382 KB\n",
      "    pixman-0.40.0              |       h2bbff1b_1         402 KB\n",
      "    pydotplus-2.0.2            |             py_3          23 KB\n",
      "    pytz-2022.7                |   py39haa95532_0         210 KB\n",
      "    tenacity-8.2.2             |   py39haa95532_0          37 KB\n",
      "    typing-extensions-4.7.1    |   py39haa95532_0          10 KB\n",
      "    typing_extensions-4.7.1    |   py39haa95532_0          57 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cairo              pkgs/main/win-64::cairo-1.16.0-he04af86_2 \n",
      "  colorama           pkgs/main/win-64::colorama-0.4.6-py39haa95532_0 \n",
      "  expat              pkgs/main/win-64::expat-2.5.0-hd77b12b_0 \n",
      "  fribidi            pkgs/main/win-64::fribidi-1.0.10-h62dcd97_0 \n",
      "  getopt-win32       pkgs/main/win-64::getopt-win32-0.1-h2bbff1b_0 \n",
      "  glib               pkgs/main/win-64::glib-2.69.1-h5dc1a3c_1 \n",
      "  graphite2          pkgs/main/win-64::graphite2-1.3.14-hd77b12b_1 \n",
      "  graphviz           pkgs/main/win-64::graphviz-2.50.0-hdb8b0d4_0 \n",
      "  gts                pkgs/main/win-64::gts-0.7.6-h63ab5a1_3 \n",
      "  harfbuzz           pkgs/main/win-64::harfbuzz-4.3.0-hb646838_1 \n",
      "  libffi             pkgs/main/win-64::libffi-3.4.4-hd77b12b_0 \n",
      "  libgd              pkgs/main/win-64::libgd-2.3.3-ha43c60c_1 \n",
      "  numexpr            pkgs/main/win-64::numexpr-2.8.4-py39h5b0cc5e_0 \n",
      "  pango              pkgs/main/win-64::pango-1.50.7-h78c2152_0 \n",
      "  pcre               pkgs/main/win-64::pcre-8.45-hd77b12b_0 \n",
      "  pixman             pkgs/main/win-64::pixman-0.40.0-h2bbff1b_1 \n",
      "  pydotplus          pkgs/main/noarch::pydotplus-2.0.2-py_3 \n",
      "  pytz               pkgs/main/win-64::pytz-2022.7-py39haa95532_0 \n",
      "  tenacity           pkgs/main/win-64::tenacity-8.2.2-py39haa95532_0 \n",
      "  typing_extensions  pkgs/main/win-64::typing_extensions-4.7.1-py39haa95532_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2023.01.10-haa95532_0 --> 2023.08.22-haa95532_0 \n",
      "  certifi                          2022.12.7-py39haa95532_0 --> 2023.7.22-py39haa95532_0 \n",
      "  openssl                                 1.1.1t-h2bbff1b_0 --> 1.1.1w-h2bbff1b_0 \n",
      "  typing-extensions                    4.3.0-py39haa95532_0 --> 4.7.1-py39haa95532_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "expat-2.5.0          | 225 KB    |            |   0% \n",
      "\n",
      "libgd-2.3.3          | 314 KB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "gts-0.7.6            | 181 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pydotplus-2.0.2      | 23 KB     |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphite2-1.3.14     | 91 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytz-2022.7          | 210 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.7.22    | 154 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "getopt-win32-0.1     | 19 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numexpr-2.8.4        | 127 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fribidi-1.0.10       | 63 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphviz-2.50.0      | 903 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 5.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tenacity-8.2.2       | 37 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pixman-0.40.0        | 402 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "harfbuzz-4.3.0       | 855 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 123 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typing-extensions-4. | 10 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre-8.45            | 382 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.4         | 113 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "expat-2.5.0          | 225 KB    | 7          |   7% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytz-2022.7          | 210 KB    | 7          |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pydotplus-2.0.2      | 23 KB     | ######8    |  68% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libgd-2.3.3          | 314 KB    | 5          |   5% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphite2-1.3.14     | 91 KB     | #7         |  18% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "gts-0.7.6            | 181 KB    | 8          |   9% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.7.22    | 154 KB    | #          |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "getopt-win32-0.1     | 19 KB     | ########6  |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphviz-2.50.0      | 903 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 5.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tenacity-8.2.2       | 37 KB     | ####3      |  43% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numexpr-2.8.4        | 127 KB    | #2         |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "harfbuzz-4.3.0       | 855 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fribidi-1.0.10       | 63 KB     | ##5        |  25% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 5.5 MB    | ####5      |  46% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pixman-0.40.0        | 402 KB    | 3          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typing-extensions-4. | 10 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre-8.45            | 382 KB    | 4          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 123 KB    | #2         |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.4         | 113 KB    | #4         |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "expat-2.5.0          | 225 KB    | ########## | 100% \n",
      "expat-2.5.0          | 225 KB    | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pydotplus-2.0.2      | 23 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pydotplus-2.0.2      | 23 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytz-2022.7          | 210 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytz-2022.7          | 210 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphite2-1.3.14     | 91 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphite2-1.3.14     | 91 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libgd-2.3.3          | 314 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "libgd-2.3.3          | 314 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "gts-0.7.6            | 181 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "gts-0.7.6            | 181 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "getopt-win32-0.1     | 19 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.7.22    | 154 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "certifi-2023.7.22    | 154 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tenacity-8.2.2       | 37 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tenacity-8.2.2       | 37 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphviz-2.50.0      | 903 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "graphviz-2.50.0      | 903 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numexpr-2.8.4        | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "numexpr-2.8.4        | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fribidi-1.0.10       | 63 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fribidi-1.0.10       | 63 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "harfbuzz-4.3.0       | 855 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "harfbuzz-4.3.0       | 855 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 5.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 5.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "typing-extensions-4. | 10 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pixman-0.40.0        | 402 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pixman-0.40.0        | 402 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 123 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 123 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre-8.45            | 382 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pcre-8.45            | 382 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.4         | 113 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libffi-3.4.4         | 113 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                      \n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/win-64::anaconda-client==1.11.0=py39haa95532_0\n",
      "  - defaults/win-64::anaconda==custom=py39_1\n",
      "  - defaults/win-64::anaconda-navigator==2.4.0=py39haa95532_0\n",
      "  - defaults/win-64::anaconda-project==0.11.1=py39haa95532_0\n",
      "  - defaults/noarch::argon2-cffi==21.3.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::arrow==1.2.2=pyhd3eb1b0_0\n",
      "  - defaults/win-64::astroid==2.11.7=py39haa95532_0\n",
      "  - defaults/noarch::babel==2.9.1=pyhd3eb1b0_0\n",
      "  - defaults/win-64::bkcharts==0.2=py39haa95532_1\n",
      "  - defaults/win-64::black==22.6.0=py39haa95532_0\n",
      "  - defaults/win-64::bokeh==2.4.3=py39haa95532_0\n",
      "  - defaults/win-64::click==8.0.4=py39haa95532_0\n",
      "  - defaults/win-64::conda==23.1.0=py39haa95532_0\n",
      "  - defaults/win-64::conda-build==3.22.0=py39haa95532_0\n",
      "  - defaults/win-64::conda-package-handling==1.9.0=py39h8cc25b3_0\n",
      "  - defaults/win-64::conda-repo-cli==1.0.20=py39haa95532_0\n",
      "  - defaults/noarch::conda-token==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-verify==3.4.2=py_1\n",
      "  - defaults/noarch::cookiecutter==1.7.3=pyhd3eb1b0_0\n",
      "  - defaults/win-64::dask==2022.7.0=py39haa95532_0\n",
      "  - defaults/win-64::datashader==0.14.1=py39haa95532_0\n",
      "  - defaults/win-64::distributed==2022.7.0=py39haa95532_0\n",
      "  - defaults/noarch::flask==1.1.2=pyhd3eb1b0_0\n",
      "  - defaults/win-64::holoviews==1.15.0=py39haa95532_0\n",
      "  - defaults/win-64::hvplot==0.8.0=py39haa95532_0\n",
      "  - defaults/noarch::intake==0.6.5=pyhd3eb1b0_0\n",
      "  - defaults/win-64::ipykernel==6.15.2=py39haa95532_0\n",
      "  - defaults/win-64::ipython==7.31.1=py39haa95532_1\n",
      "  - defaults/noarch::ipywidgets==7.6.5=pyhd3eb1b0_1\n",
      "  - defaults/noarch::jinja2-time==0.2.0=pyhd3eb1b0_3\n",
      "  - defaults/win-64::jupyter==1.0.0=py39haa95532_8\n",
      "  - defaults/win-64::jupyterlab==3.4.4=py39haa95532_0\n",
      "  - defaults/noarch::jupyterlab_server==2.10.3=pyhd3eb1b0_1\n",
      "  - defaults/noarch::jupyter_console==6.4.3=pyhd3eb1b0_0\n",
      "  - defaults/win-64::jupyter_server==1.18.1=py39haa95532_0\n",
      "  - defaults/win-64::navigator-updater==0.3.0=py39haa95532_0\n",
      "  - defaults/noarch::nbclassic==0.3.5=pyhd3eb1b0_0\n",
      "  - defaults/noarch::nltk==3.7=pyhd3eb1b0_0\n",
      "  - defaults/win-64::notebook==6.4.12=py39haa95532_0\n",
      "  - defaults/win-64::numpydoc==1.4.0=py39haa95532_0\n",
      "  - defaults/win-64::pandas==1.4.4=py39hd77b12b_0\n",
      "  - defaults/win-64::panel==0.13.1=py39haa95532_0\n",
      "  - defaults/win-64::plotly==5.9.0=py39haa95532_0\n",
      "  - defaults/win-64::pylint==2.14.5=py39haa95532_0\n",
      "  - defaults/noarch::pyls-spyder==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::pytables==3.6.1=py39h56d22b6_1\n",
      "  - defaults/win-64::pytest==7.1.2=py39haa95532_0\n",
      "  - defaults/noarch::python-lsp-black==1.0.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::python-lsp-server==1.3.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::qtconsole==5.2.2=pyhd3eb1b0_0\n",
      "  - defaults/win-64::scrapy==2.6.2=py39haa95532_0\n",
      "  - defaults/noarch::seaborn==0.11.2=pyhd3eb1b0_0\n",
      "  - defaults/win-64::sphinx==5.0.2=py39haa95532_0\n",
      "  - defaults/win-64::spyder==5.2.2=py39haa95532_1\n",
      "  - defaults/win-64::spyder-kernels==2.2.1=py39haa95532_0\n",
      "  - defaults/win-64::statsmodels==0.13.2=py39h2bbff1b_0\n",
      "  - defaults/win-64::tqdm==4.64.1=py39haa95532_0\n",
      "  - defaults/win-64::twisted==22.2.0=py39h2bbff1b_1\n",
      "  - defaults/win-64::typing-extensions==4.3.0=py39haa95532_0\n",
      "  - defaults/win-64::widgetsnbextension==3.5.2=py39haa95532_0\n",
      "  - defaults/noarch::xarray==0.20.1=pyhd3eb1b0_1\n",
      "  - defaults/win-64::_anaconda_depends==2022.10=py39_2\n",
      "  - defaults/win-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39haa95532_0\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.1.0\n",
      "  latest version: 23.7.4\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.7.4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load general utilities\n",
    "# ----------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "# Load sklearn utilities\n",
    "# ----------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, brier_score_loss, mean_squared_error, r2_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Load classifiers\n",
    "# ----------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Other Packages\n",
    "# --------------\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "## from gurobipy import *\n",
    "# from sklearn.externals.six import StringIO\n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "!conda install -y pydotplus\n",
    "import pydotplus\n",
    "#from scipy.interpolate import spline\n",
    "\n",
    "# Load debugger, if required\n",
    "#import pixiedust\n",
    "pd.options.mode.chained_assignment = None #'warn'\n",
    "\n",
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function that, given a CVGridSearch object, finds the percentage difference between the best and worst scores\n",
    "def find_score_variation(cv_model):\n",
    "    all_scores = cv_model.cv_results_['mean_test_score']\n",
    "    return( np.abs((max(all_scores) - min(all_scores))) * 100 / max(all_scores) )\n",
    "\n",
    "    '''\n",
    "    which_min_score = np.argmin(all_scores)\n",
    "\n",
    "    all_perc_diff = []\n",
    "\n",
    "    try:\n",
    "        all_perc_diff.append( np.abs(all_scores[which_min_score - 1] - all_scores[which_min_score])*100 / min(all_scores) )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        all_perc_diff.append( np.abs(all_scores[which_min_score + 1] - all_scores[which_min_score])*100 / min(all_scores) )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return ( np.mean(all_perc_diff) )\n",
    "    '''\n",
    "\n",
    "# Define a function that checks, given a CVGridSearch object,\n",
    "# whether the optimal parameters lie on the edge of the search\n",
    "# grid\n",
    "def find_opt_params_on_edge(cv_model):\n",
    "    out = False\n",
    "\n",
    "    for i in cv_model.param_grid:\n",
    "        if cv_model.best_params_[i] in [ cv_model.param_grid[i][0], cv_model.param_grid[i][-1] ]:\n",
    "            out = True\n",
    "            break\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a default random seed and an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "default_seed = 1\n",
    "output_file = \"output_sample_ravi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to print a line to our output file\n",
    "def dump_to_output(key, value):\n",
    "    with open(output_file, \"a\") as f:\n",
    "        f.write(\",\".join([str(default_seed), key, str(value)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and engineer the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Week 2/PickleData/ret_data.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32396\\302954290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read the data and features from the pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontinuous_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"../Week 2/PickleData/ret_data.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Week 2/PickleData/ret_data.pickle'"
     ]
    }
   ],
   "source": [
    "# Read the data and features from the pickle\n",
    "data, discrete_features, continuous_features, ret_cols = pickle.load( open( \"../Week 2/PickleData/ret_data.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the outcome\n",
    "data[\"outcome\"] = data.loan_status.isin([\"Charged Off\", \"Default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a feature for the length of a person's credit history at the time the loan is issued\n",
    "data['cr_hist'] = (data.issue_d - data.earliest_cr_line) / np.timedelta64(1, 'M')\n",
    "continuous_features.append('cr_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly assign each row to a training and test set. We do this now\n",
    "# because we will be fitting a variety of models on various time periods,\n",
    "# and we would like every period to use the *same* training/test split\n",
    "np.random.seed(default_seed)\n",
    "data['train'] = np.random.choice([True, False], size = len(data), p = [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a matrix of features and outcomes, with dummies. Record the names of the dummies for later use\n",
    "X_continuous = data[continuous_features].values\n",
    "\n",
    "X_discrete = pd.get_dummies(data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n",
    "discrete_features_dummies = X_discrete.columns.tolist()\n",
    "X_discrete = X_discrete.values\n",
    "\n",
    "X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n",
    "\n",
    "y = data.outcome.values\n",
    "\n",
    "train = data.train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare functions to fit and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(data_subset = np.array([True]*len(data)),\n",
    "                    n_samples_train = 25000,\n",
    "                    n_samples_test = 10000,\n",
    "                    feature_subset = None,\n",
    "                    date_range_train = (data.issue_d.min(), data.issue_d.max()),\n",
    "                    date_range_test = (data.issue_d.min(), data.issue_d.max()),\n",
    "                    random_state = default_seed):\n",
    "    '''\n",
    "    This function will prepare the data for classification or regression.\n",
    "    It expects the following parameters:\n",
    "      - data_subset: a numpy array with as many entries as rows in the\n",
    "                     dataset. Each entry should be True if that row\n",
    "                     should be used, or False if it should be ignored\n",
    "      - n_samples_train: the total number of samples to be used for training.\n",
    "                         Will trigger an error if this number is larger than\n",
    "                         the number of rows available after all filters have\n",
    "                         been applied\n",
    "      - n_samples_test: as above for testing\n",
    "      - feature_subect: A list containing the names of the features to be\n",
    "                        used in the model. In None, all features in X are\n",
    "                        used\n",
    "      - date_range_train: a tuple containing two dates. All rows with loans\n",
    "                          issued outside of these two dates will be ignored in\n",
    "                          training\n",
    "      - date_range_test: as above for testing\n",
    "      - random_state: the random seed to use when selecting a subset of rows\n",
    "\n",
    "    Note that this function assumes the data has a \"Train\" column, and will\n",
    "    select all training rows from the rows with \"True\" in that column, and all\n",
    "    the testing rows from those with a \"False\" in that column.\n",
    "\n",
    "    This function returns a dictionary with the following entries\n",
    "      - X_train: the matrix of training data\n",
    "      - y_train: the array of training labels\n",
    "      - train_set: a Boolean vector with as many entries as rows in the data\n",
    "                  that denotes the rows that were used in the train set\n",
    "      - X_test: the matrix of testing data\n",
    "      - y_test: the array of testing labels\n",
    "      - test_set: a Boolean vector with as many entries as rows in the data\n",
    "                  that denotes the rows that were used in the test set\n",
    "    '''\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Filter down the data to the required date range, and downsample\n",
    "    # as required\n",
    "    filter_train = ( train & (data.issue_d >= date_range_train[0]) &\n",
    "                            (data.issue_d <= date_range_train[1]) & data_subset ).values\n",
    "    filter_test = ( (train == False) & (data.issue_d >= date_range_test[0])\n",
    "                            & (data.issue_d <= date_range_test[1]) & data_subset ).values\n",
    "\n",
    "    filter_train[ np.random.choice( np.where(filter_train)[0], size = filter_train.sum()\n",
    "                                   - n_samples_train, replace = False ) ] = False\n",
    "    filter_test[ np.random.choice( np.where(filter_test)[0], size = filter_test.sum()\n",
    "                                   - n_samples_test, replace = False ) ] = False\n",
    "\n",
    "    # Prepare the training and test set\n",
    "    X_train = X[ filter_train , :]\n",
    "    X_test = X[ filter_test, :]\n",
    "    if feature_subset != None:\n",
    "        cols = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n",
    "                                                     if j.split(\"::\")[0] in feature_subset]\n",
    "        X_train = X_train[ : , cols ]\n",
    "        X_test = X_test[ : , cols ]\n",
    "\n",
    "    y_train = y[ filter_train ]\n",
    "    y_test = y[ filter_test ]\n",
    "\n",
    "    # Scale the variables\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # return training and testing data\n",
    "    out = {'X_train':X_train, 'y_train':y_train, 'train_set':filter_train,\n",
    "           'X_test':X_test, 'y_test':y_test, 'test_set':filter_test}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit_classification(model, data_dict,\n",
    "                          cv_parameters = {},\n",
    "                          model_name = None,\n",
    "                          random_state = default_seed,\n",
    "                          output_to_file = True,\n",
    "                          print_to_screen = True):\n",
    "    '''\n",
    "    This function will fit a classification model to data and print various evaluation\n",
    "    measures. It expects the following parameters\n",
    "      - model: an sklearn model object\n",
    "      - data_dict: the dictionary containing both training and testing data;\n",
    "                   returned by the prepare_data function\n",
    "      - cv_parameters: a dictionary of parameters that should be optimized\n",
    "                       over using cross-validation. Specifically, each named\n",
    "                       entry in the dictionary should correspond to a parameter,\n",
    "                       and each element should be a list containing the values\n",
    "                       to optimize over\n",
    "      - model_name: the name of the model being fit, for printouts\n",
    "      - random_state: the random seed to use\n",
    "      - output_to_file: if the results will be saved to the output file\n",
    "      - print_to_screen: if the results will be printed on screen\n",
    "\n",
    "    If the model provided does not have a predict_proba function, we will\n",
    "    simply print accuracy diagnostics and return.\n",
    "\n",
    "    If the model provided does have a predict_proba function, we first\n",
    "    figure out the optimal threshold that maximizes the accuracy and\n",
    "    print out accuracy diagnostics. We then print an ROC curve, sensitivity/\n",
    "    specificity curve, and calibration curve.\n",
    "\n",
    "    This function returns a dictionary with the following entries\n",
    "      - model: the best fitted model\n",
    "      - y_pred: predictions for the test set\n",
    "      - y_pred_probs: probability predictions for the test set, if the model\n",
    "                      supports them\n",
    "      - y_pred_score: prediction scores for the test set, if the model does not\n",
    "                      output probabilities.\n",
    "    '''\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # --------------------------\n",
    "    #   Step 1 - Load the data\n",
    "    # --------------------------\n",
    "    \n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "\n",
    "    X_test = data_dict['X_test']\n",
    "    y_test = data_dict['y_test']\n",
    "\n",
    "    filter_train = data_dict['train_set']\n",
    "\n",
    "    # --------------------------\n",
    "    #   Step 2 - Fit the model\n",
    "    # --------------------------\n",
    "\n",
    "    cv_model = GridSearchCV(model, cv_parameters)\n",
    "\n",
    "    start_time = time.time()\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    best_model = cv_model.best_estimator_\n",
    "\n",
    "    if print_to_screen:\n",
    "\n",
    "        if model_name != None:\n",
    "            print(\"=========================================================\")\n",
    "            print(\"  Model: \" + model_name)\n",
    "            print(\"=========================================================\")\n",
    "\n",
    "        print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        print(\"Optimal parameters:\")\n",
    "        print(cv_model.best_params_)\n",
    "        print(\"\")\n",
    "\n",
    "    # -------------------------------\n",
    "    #   Step 3 - Evaluate the model\n",
    "    # -------------------------------\n",
    "\n",
    "    # If possible, make probability predictions\n",
    "    try:\n",
    "        y_pred_probs = best_model.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "\n",
    "        probs_predicted = True\n",
    "    except:\n",
    "        probs_predicted = False\n",
    "\n",
    "    # Make predictions; if we were able to find probabilities, use\n",
    "    # the threshold that maximizes the accuracy in the training set.\n",
    "    # If not, just use the learner's predict function\n",
    "    if probs_predicted:\n",
    "        y_train_pred_probs = best_model.predict_proba(X_train)[:,1]\n",
    "        fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_pred_probs)\n",
    "\n",
    "        true_pos_train = tpr_train*(y_train.sum())\n",
    "        true_neg_train = (1 - fpr_train) *(1-y_train).sum()\n",
    "\n",
    "        best_threshold_index = np.argmax(true_pos_train + true_neg_train)\n",
    "        best_threshold = 1 if best_threshold_index == 0 else thresholds_train[ best_threshold_index ]\n",
    "\n",
    "        if print_to_screen:\n",
    "            print(\"Accuracy-maximizing threshold was: \" + str(best_threshold))\n",
    "\n",
    "        y_pred = (y_pred_probs > best_threshold)\n",
    "    else:\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "    if print_to_screen:\n",
    "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred, target_names =['No default', 'Default'], digits = 4))\n",
    "\n",
    "    if print_to_screen:\n",
    "        if probs_predicted:\n",
    "            plt.figure(figsize = (13, 4.5))\n",
    "            plt.subplot(2, 2, 1)\n",
    "\n",
    "            plt.title(\"ROC Curve (AUC = %0.2f)\"% roc_auc_score(y_test, y_pred_probs))\n",
    "            plt.plot(fpr, tpr, 'b')\n",
    "            plt.plot([0,1],[0,1],'r--')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "\n",
    "            plt.plot(thresholds, tpr, 'b', label = 'Sensitivity')\n",
    "            plt.plot(thresholds, 1 -fpr, 'r', label = 'Specificity')\n",
    "            plt.legend(loc = 'lower right')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.xlabel('Threshold')\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "\n",
    "            fp_0, mpv_0 = calibration_curve(y_test, y_pred_probs, n_bins = 10)\n",
    "            plt.plot([0,1], [0,1], 'k:', label='Perfectly calibrated')\n",
    "            plt.plot(mpv_0, fp_0, 's-')\n",
    "            plt.ylabel('Fraction of Positives')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.legend(loc ='upper left')\n",
    "\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.hist(y_pred_probs, range=(0, 1), bins=10, histtype=\"step\", lw=2)\n",
    "            plt.xlim([0,1]); plt.ylim([0,20000])\n",
    "            plt.xlabel('Mean Predicted Probability')\n",
    "            plt.ylabel('Count')\n",
    "\n",
    "            #plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # Additional Score Check\n",
    "    if probs_predicted:\n",
    "        y_train_score = y_train_pred_probs\n",
    "    else:\n",
    "        y_train_score = best_model.decision_function(X_train)\n",
    "\n",
    "    tau, p_value = kendalltau(y_train_score, data.grade[filter_train])\n",
    "    if print_to_screen:\n",
    "        print(\"\")\n",
    "        print(\"Similarity to LC grade ranking: \", tau)\n",
    "\n",
    "    if probs_predicted:\n",
    "        brier_score = brier_score_loss(y_test, y_pred_probs)\n",
    "        if print_to_screen:\n",
    "            print(\"Brier score:\", brier_score)\n",
    "\n",
    "    # Return the model predictions, and the\n",
    "    # test set\n",
    "    # -------------------------------------\n",
    "    out = {'model':best_model, 'y_pred_labels':y_pred}\n",
    "\n",
    "    if probs_predicted:\n",
    "        out.update({'y_pred_probs':y_pred_probs})\n",
    "    else:\n",
    "        y_pred_score = best_model.decision_function(X_test)\n",
    "        out.update({'y_pred_score':y_pred_score})\n",
    "\n",
    "    # Output results to file\n",
    "    # ----------------------\n",
    "    if probs_predicted and output_to_file:\n",
    "        # Check whether any of the CV parameters are on the edge of\n",
    "        # the search space\n",
    "        opt_params_on_edge = find_opt_params_on_edge(cv_model)\n",
    "        dump_to_output(model_name + \"::search_on_edge\", opt_params_on_edge)\n",
    "        if print_to_screen:\n",
    "            print(\"Were parameters on edge? : \" + str(opt_params_on_edge))\n",
    "\n",
    "        # Find out how different the scores are for the different values\n",
    "        # tested for by cross-validation. If they're not too different, then\n",
    "        # even if the parameters are off the edge of the search grid, we should\n",
    "        # be ok\n",
    "        score_variation = find_score_variation(cv_model)\n",
    "        dump_to_output(model_name + \"::score_variation\", score_variation)\n",
    "        if print_to_screen:\n",
    "            print(\"Score variations around CV search grid : \" + str(score_variation))\n",
    "\n",
    "        # Print out all the scores\n",
    "        dump_to_output(model_name + \"::all_cv_scores\", str(cv_model.cv_results_['mean_test_score']))\n",
    "        if print_to_screen:\n",
    "            print( str(cv_model.cv_results_['mean_test_score']) )\n",
    "\n",
    "        # Dump the AUC to file\n",
    "        dump_to_output(model_name + \"::roc_auc\", roc_auc_score(y_test, y_pred_probs) )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Baseline models\n",
    "See how well we do using grade or interest rate only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = prepare_data(feature_subset=['grade'])\n",
    "grade_only_logistic = LogisticRegression(penalty = 'l2', C=np.inf, solver='lbfgs')\n",
    "\n",
    "grade_only_logistic = fit_classification(grade_only_logistic,data_dict,\n",
    "                                         model_name = 'Grade only logistic l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = prepare_data(feature_subset=['int_rate'])\n",
    "interest_only_logistic = LogisticRegression(penalty = 'l2', C=np.inf, solver='lbfgs')\n",
    "\n",
    "interest_only_logistic = fit_classification(interest_only_logistic, data_dict,\n",
    "                                   model_name = 'Interest rate only logistics l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4- Test models without grade or interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_features = [i for i in discrete_features + continuous_features if i not in [\"grade\", \"int_rate\", \"installment\"]]\n",
    "data_dict = prepare_data(feature_subset = final_features)\n",
    "\n",
    "all_features = pd.Series(continuous_features + discrete_features_dummies)\n",
    "idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n",
    "                                                     if j.split(\"::\")[0] in final_features]\n",
    "selected_features = all_features[idx]\n",
    "selected_features.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ridge_classifier = RidgeClassifier()\n",
    "cv_parameters = {\"alpha\":np.logspace(-4, 4, num = 10)}\n",
    "\n",
    "ridge_classifier = fit_classification(ridge_classifier, data_dict,\n",
    "                             cv_parameters = cv_parameters, model_name = \"Ridge Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb = fit_classification(gnb, data_dict,\n",
    "                model_name = \"Gaussian Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $l_1$ penalized logistic regression\n",
    "(Takes a couple of minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Use version loaded from pickle\n",
    "l1_logistic = LogisticRegression(penalty = 'l1',solver='liblinear')\n",
    "cv_parameters = {\"C\":np.logspace(0, 6, num = 10)}\n",
    "\n",
    "l1_logistic = fit_classification(l1_logistic, data_dict,\n",
    "                       cv_parameters = cv_parameters, model_name = \"l1 Penalized Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot top 3 features with the most positive (and negative) weights\n",
    "top_and_bottom_idx = list(np.argsort(l1_logistic['model'].coef_)[0,:3]) + list(np.argsort(l1_logistic['model'].coef_)[0,-3:])\n",
    "bplot = pd.Series(l1_logistic['model'].coef_[0,top_and_bottom_idx])\n",
    "xticks = selected_features[top_and_bottom_idx]\n",
    "p1 = bplot.plot(kind='bar',rot=-30,ylim=(-2,3))\n",
    "p1.set_xticklabels(xticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $l_2$ penalized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Use version loaded from pickle\n",
    "l2_logistic = LogisticRegression(penalty = 'l2')\n",
    "cv_parameters = {\"C\":np.logspace(-4, 4, num = 10)}\n",
    "\n",
    "l2_logistic = fit_classification(l2_logistic, data_dict,\n",
    "                       cv_parameters = cv_parameters, model_name = \"l2 Penalized Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## plot top 3 features with the most positive (and negative) weights\n",
    "top_and_bottom_idx = list(np.argsort(l2_logistic['model'].coef_)[0,:3]) + list(np.argsort(l2_logistic['model'].coef_)[0,-3:])\n",
    "bplot = pd.Series(l2_logistic['model'].coef_[0,top_and_bottom_idx])\n",
    "xticks = selected_features[top_and_bottom_idx]\n",
    "p1 = bplot.plot(kind='bar',rot=-30,ylim=(-2,3))\n",
    "p1.set_xticklabels(xticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Use version loaded from pickle\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "cv_parameters = {'min_samples_leaf':[500,600,700,800,900,1000, 1100, 1200, 1300]}\n",
    "\n",
    "decision_tree = fit_classification(decision_tree, data_dict,\n",
    "                         cv_parameters = cv_parameters, model_name = \"Decision tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "# Zooming-in is allowed by double click\n",
    "!conda install -c conda-forge pygraphviz -y\n",
    "!conda install python-graphviz pydot -y\n",
    "import graphviz\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(decision_tree['model'], out_file=dot_data,\n",
    "                feature_names=selected_features,filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "Takes nearly 10 minutes given the large data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Use version loaded from pickle\n",
    "random_forest = RandomForestClassifier()\n",
    "cv_parameters = {'min_samples_leaf':[1, 2, 3, 5, 8, 13, 17, 20, 40], 'n_estimators': [35, 60, 80, 100, 150] }\n",
    "\n",
    "random_forest_model = fit_classification(random_forest, data_dict,\n",
    "                                   cv_parameters=cv_parameters, model_name=\"Random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Plot top 6 most significant features\n",
    "top_idx = list(np.argsort(random_forest_model['model'].feature_importances_)[-6:])\n",
    "bplot = pd.Series(random_forest_model['model'].feature_importances_[top_idx])\n",
    "xticks = selected_features[top_idx]\n",
    "p2 = bplot.plot(kind='bar',rot=-30,ylim=(0,0.2))\n",
    "p2.set_xticklabels(xticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## A decision tree trained on the scores of random forest\n",
    "trepin_tree = DecisionTreeClassifier(min_samples_leaf = 100, max_depth = 4)\n",
    "trepin_tree.fit(random_forest_model['y_pred_probs'].reshape(-1,1),data_dict['y_test'])\n",
    "dot_data = StringIO()\n",
    "export_graphviz(trepin_tree, out_file=dot_data,\n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged trees\n",
    "Takes a very long time for the whole LC data set!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use saved version\n",
    "bagged_trees = RandomForestClassifier(max_features = 1.0)\n",
    "cv_parameters = {'min_samples_leaf':[5, 10, 25, 50, 75, 100, 200], 'n_estimators': [60, 100, 150, 200, 300] }\n",
    "\n",
    "bagged_trees_model = fit_classification(bagged_trees, data_dict,\n",
    "                                  cv_parameters=cv_parameters, model_name=\"Bagged trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot top 6 most significant features\n",
    "top_idx = list(np.argsort(bagged_trees_model['model'].feature_importances_)[-6:])\n",
    "bplot = pd.Series(bagged_trees_model['model'].feature_importances_[top_idx])\n",
    "xticks = selected_features[top_idx]\n",
    "p2 = bplot.plot(kind='bar',rot=-30,ylim=(0,0.2))\n",
    "p2.set_xticklabels(xticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a \"dill\" of all your models for later use\n",
    "If you ran complicated models that has taken considerable time, you can save these models in a dump of the whole session (not just the data) using a version of pickling called \"dill\" as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install dill -y\n",
    "import dill\n",
    "dill.dump_session('finalweek3.pkl')\n",
    "\n",
    "#The above command dumps a file in the current directory which you can load later as follows\n",
    "# import dill\n",
    "# dill.load_session('week3.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
